{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LUA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056190147995949\t\n",
       "(1,1,.,.) = \n",
       " 0.01 *\n",
       "   0.1434  0.6162 -0.0147\n",
       "   0.4836  0.1553  0.7928\n",
       "  -0.1711 -0.0319  0.2181\n",
       "\n",
       "(1,2,.,.) = \n",
       " 0.01 *\n",
       "   1.4294  0.8828  1.4865\n",
       "   0.9324  0.8405 -0.0166\n",
       "   0.2223  0.4914  1.3700\n",
       "[torch.CudaTensor of size 1x2x3x3]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'nn'\n",
    "require 'lua_level.FocalLoss'\n",
    "torch.setdefaulttensortype('torch.CudaTensor')\n",
    "criterion = FocalLoss()\n",
    "input = torch.Tensor({{{{-1.1957, -0.4597,  1.6950},\n",
    "                        {-0.5970, -1.1598, -0.3070},\n",
    "                        { 0.5639,  1.3726, -1.0021}},\n",
    "\n",
    "                       {{ 0.1081, -0.2382,  0.1398},\n",
    "                        {-0.2022, -0.2699,  1.6455},\n",
    "                        {-0.993, -0.5881,  0.0745}}}})\n",
    "target = torch.Tensor({{{{ 0.,  0.,  1.},\n",
    "                         { 0.,  0.,  0.},\n",
    "                         { 1.,  1.,  0.}},\n",
    "\n",
    "                        {{ 0.,  0.,  0.},\n",
    "                         { 0.,  0.,  1.},\n",
    "                         { 0.,  0.,  0.}}}})\n",
    "\n",
    "net = nn.Sequential()\n",
    "net:add(nn.Sigmoid())\n",
    "\n",
    "out = net:forward(input)\n",
    "loss = criterion:forward(out, target)\n",
    "net:zeroGradParameters()\n",
    "grad = criterion:backward(out, target)\n",
    "net:backward(input, grad)\n",
    "\n",
    "print(loss)\n",
    "print(net.gradInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test C level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056190140545368\t\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       " 0.01 *\n",
       "   0.1434  0.6162 -0.0147\n",
       "   0.4836  0.1553  0.7928\n",
       "  -0.1711 -0.0319  0.2181\n",
       "\n",
       "(1,2,.,.) = \n",
       " 0.01 *\n",
       "   1.4294  0.8828  1.4865\n",
       "   0.9324  0.8405 -0.0166\n",
       "   0.2223  0.4914  1.3700\n",
       "[torch.FloatTensor of size 1x2x3x3]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'nn'\n",
    "torch.setdefaulttensortype('torch.FloatTensor')\n",
    "criterion = nn.FLCriterion(0.25, 2)\n",
    "input = torch.Tensor({{{{-1.1957, -0.4597,  1.6950},\n",
    "                        {-0.5970, -1.1598, -0.3070},\n",
    "                        { 0.5639,  1.3726, -1.0021}},\n",
    "\n",
    "                       {{ 0.1081, -0.2382,  0.1398},\n",
    "                        {-0.2022, -0.2699,  1.6455},\n",
    "                        {-0.993, -0.5881,  0.0745}}}})\n",
    "target = torch.Tensor({{{{ 0.,  0.,  1.},\n",
    "                         { 0.,  0.,  0.},\n",
    "                         { 1.,  1.,  0.}},\n",
    "\n",
    "                        {{ 0.,  0.,  0.},\n",
    "                         { 0.,  0.,  1.},\n",
    "                         { 0.,  0.,  0.}}}})\n",
    "net = nn.Sequential()\n",
    "net:add(nn.Sigmoid())\n",
    "\n",
    "out = net:forward(input)\n",
    "loss = criterion:forward(out, target)\n",
    "net:zeroGradParameters()\n",
    "grad = criterion:backward(out, target)\n",
    "net:backward(input, grad)\n",
    "\n",
    "print(loss)\n",
    "print(net.gradInput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CUDA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056190140545368\t\n",
       "(1,1,.,.) = \n",
       " 0.01 *\n",
       "   0.1434  0.6162 -0.0147\n",
       "   0.4836  0.1553  0.7928\n",
       "  -0.1711 -0.0319  0.2181\n",
       "\n",
       "(1,2,.,.) = \n",
       " 0.01 *\n",
       "   1.4294  0.8828  1.4865\n",
       "   0.9324  0.8405 -0.0166\n",
       "   0.2223  0.4914  1.3700\n",
       "[torch.CudaTensor of size 1x2x3x3]\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'nn'\n",
    "require 'cunn'\n",
    "torch.setdefaulttensortype('torch.CudaTensor')\n",
    "criterion = nn.FLCriterion(0.25, 2):cuda()\n",
    "input = torch.Tensor({{{{-1.1957, -0.4597,  1.6950},\n",
    "                        {-0.5970, -1.1598, -0.3070},\n",
    "                        { 0.5639,  1.3726, -1.0021}},\n",
    "\n",
    "                       {{ 0.1081, -0.2382,  0.1398},\n",
    "                        {-0.2022, -0.2699,  1.6455},\n",
    "                        {-0.993, -0.5881,  0.0745}}}})\n",
    "target = torch.Tensor({{{{ 0.,  0.,  1.},\n",
    "                         { 0.,  0.,  0.},\n",
    "                         { 1.,  1.,  0.}},\n",
    "\n",
    "                        {{ 0.,  0.,  0.},\n",
    "                         { 0.,  0.,  1.},\n",
    "                         { 0.,  0.,  0.}}}})\n",
    "net = nn.Sequential()\n",
    "net:add(nn.Sigmoid())\n",
    "\n",
    "out = net:forward(input)\n",
    "loss = criterion:forward(out, target)\n",
    "net:zeroGradParameters()\n",
    "grad = criterion:backward(out, target)\n",
    "net:backward(input, grad)\n",
    "\n",
    "print(loss)\n",
    "print(net.gradInput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
